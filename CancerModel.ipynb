{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc1a2c8-5d49-43ca-a1fe-a192dd34e68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easyocr\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (0.17.2)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (4.10.0.84)\n",
      "Requirement already satisfied: scipy in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (1.15.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (1.26.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (10.2.0)\n",
      "Collecting scikit-image (from easyocr)\n",
      "  Downloading scikit_image-0.25.2-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr)\n",
      "  Downloading python_bidi-0.6.6-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (2.1.1)\n",
      "Collecting pyclipper (from easyocr)\n",
      "  Downloading pyclipper-1.3.0.post6-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting ninja (from easyocr)\n",
      "  Downloading ninja-1.11.1.4-py3-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->easyocr) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->easyocr) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->easyocr) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->easyocr) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->easyocr) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch->easyocr) (3.0.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->easyocr) (2.37.0)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr)\n",
      "  Downloading tifffile-2025.6.11-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->easyocr) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.0/2.9 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.4/2.9 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading ninja-1.11.1.4-py3-none-win_amd64.whl (296 kB)\n",
      "Downloading pyclipper-1.3.0.post6-cp311-cp311-win_amd64.whl (110 kB)\n",
      "Downloading python_bidi-0.6.6-cp311-cp311-win_amd64.whl (160 kB)\n",
      "Downloading scikit_image-0.25.2-cp311-cp311-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.8 MB 6.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.4/12.8 MB 5.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.1/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.9/12.8 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.7/12.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.5/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.6/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.6/12.8 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.4/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.7/12.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.3/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading tifffile-2025.6.11-py3-none-any.whl (230 kB)\n",
      "Installing collected packages: python-bidi, pyclipper, tifffile, ninja, scikit-image, easyocr\n",
      "\n",
      "   ------------- -------------------------- 2/6 [tifffile]\n",
      "   -------------------------- ------------- 4/6 [scikit-image]\n",
      "   -------------------------- ------------- 4/6 [scikit-image]\n",
      "   -------------------------- ------------- 4/6 [scikit-image]\n",
      "   -------------------------- ------------- 4/6 [scikit-image]\n",
      "   -------------------------- ------------- 4/6 [scikit-image]\n",
      "   -------------------------- ------------- 4/6 [scikit-image]\n",
      "   -------------------------- ------------- 4/6 [scikit-image]\n",
      "   -------------------------- ------------- 4/6 [scikit-image]\n",
      "   -------------------------- ------------- 4/6 [scikit-image]\n",
      "   --------------------------------- ------ 5/6 [easyocr]\n",
      "   --------------------------------- ------ 5/6 [easyocr]\n",
      "   ---------------------------------------- 6/6 [easyocr]\n",
      "\n",
      "Successfully installed easyocr-1.7.2 ninja-1.11.1.4 pyclipper-1.3.0.post6 python-bidi-0.6.6 scikit-image-0.25.2 tifffile-2025.6.11\n"
     ]
    }
   ],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5443c6f1-29d4-48b0-a473-7c1d86171d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Extracted Text: \n",
      "‚ùå Could not extract gene/variation from image text.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# === üì• Load model\n",
    "model = load_model(r\"C:\\Users\\sagni\\Downloads\\Cancer Detection\\cancer_model.h5\")\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# === üîÉ Recreate tokenizer and encoders from training data\n",
    "variants_path = r\"C:\\Users\\sagni\\Downloads\\msk-redefining-cancer-treatment\\training_variants\"\n",
    "text_path = r\"C:\\Users\\sagni\\Downloads\\msk-redefining-cancer-treatment\\training_text\"\n",
    "\n",
    "variants_df = pd.read_csv(variants_path)\n",
    "text_df = pd.read_csv(text_path, sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
    "data = pd.merge(variants_df, text_df, on=\"ID\")\n",
    "data[\"Text\"] = data[\"Text\"].fillna(\"unknown\")\n",
    "\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(data[\"Text\"])\n",
    "\n",
    "gene_encoder = LabelEncoder()\n",
    "gene_encoder.fit(data[\"Gene\"])\n",
    "\n",
    "variation_encoder = LabelEncoder()\n",
    "variation_encoder.fit(data[\"Variation\"])\n",
    "\n",
    "# === üîç Prediction function\n",
    "def predict_from_text(input_text, input_gene, input_variation):\n",
    "    seq = tokenizer.texts_to_sequences([input_text])\n",
    "    padded_seq = pad_sequences(seq, maxlen=500)\n",
    "\n",
    "    if input_gene not in gene_encoder.classes_:\n",
    "        print(f\"‚ùå Unknown gene: {input_gene}\")\n",
    "        return None\n",
    "    gene_encoded = gene_encoder.transform([input_gene])\n",
    "    gene_encoded = np.expand_dims(gene_encoded, -1)\n",
    "\n",
    "    if input_variation not in variation_encoder.classes_:\n",
    "        print(f\"‚ùå Unknown variation: {input_variation}\")\n",
    "        return None\n",
    "    var_encoded = variation_encoder.transform([input_variation])\n",
    "    var_encoded = np.expand_dims(var_encoded, -1)\n",
    "\n",
    "    prediction = model.predict([padded_seq, gene_encoded, var_encoded])\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0] + 1\n",
    "    print(f\"‚úÖ Predicted Cancer Class: {predicted_class}\")\n",
    "    return predicted_class\n",
    "\n",
    "# === üñºÔ∏è OCR and Prediction from image\n",
    "def predict_from_image(image_path):\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    result = reader.readtext(image_path, detail=0)\n",
    "    text = \" \".join(result)\n",
    "    print(f\"\\nüìù Extracted Text: {text}\")\n",
    "\n",
    "    # Basic gene/variation extractor from OCR output\n",
    "    gene = None\n",
    "    variation = None\n",
    "\n",
    "    for word in result:\n",
    "        upper_word = word.upper()\n",
    "        if upper_word in gene_encoder.classes_:\n",
    "            gene = upper_word\n",
    "        if word in variation_encoder.classes_:\n",
    "            variation = word\n",
    "\n",
    "    if gene and variation:\n",
    "        return predict_from_text(text, gene, variation)\n",
    "    else:\n",
    "        print(\"‚ùå Could not extract gene/variation from image text.\")\n",
    "        return None\n",
    "\n",
    "# === üß™ Run Prediction\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = r\"C:\\Users\\sagni\\Downloads\\Cancer Detection\\images.jpg\"  # Replace with your image path\n",
    "    predict_from_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "679caacf-6d46-4734-8720-3df2830cf58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 236ms/step - accuracy: 0.2700 - loss: 2.0899 - val_accuracy: 0.3233 - val_loss: 1.8132\n",
      "Epoch 2/5\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.3778 - loss: 1.6710 - val_accuracy: 0.4887 - val_loss: 1.4690\n",
      "Epoch 3/5\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 209ms/step - accuracy: 0.5926 - loss: 1.1734 - val_accuracy: 0.5677 - val_loss: 1.3304\n",
      "Epoch 4/5\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 209ms/step - accuracy: 0.6816 - loss: 0.9102 - val_accuracy: 0.5263 - val_loss: 1.3343\n",
      "Epoch 5/5\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 211ms/step - accuracy: 0.7635 - loss: 0.7326 - val_accuracy: 0.5639 - val_loss: 1.2820\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5678 - loss: 1.2597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Test Accuracy: 0.5805\n",
      "‚úÖ Model saved!\n",
      "‚úÖ Tokenizer saved!\n",
      "‚úÖ Gene encoder saved!\n",
      "‚úÖ Variation encoder saved!\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Install required libraries (uncomment if running in a new environment)\n",
    "# !pip install pandas scikit-learn tensorflow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, LSTM, Concatenate\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === üìÇ Load data ===\n",
    "variants_path = r\"C:\\Users\\sagni\\Downloads\\msk-redefining-cancer-treatment\\training_variants\"\n",
    "text_path = r\"C:\\Users\\sagni\\Downloads\\msk-redefining-cancer-treatment\\training_text\"\n",
    "variants_df = pd.read_csv(variants_path)\n",
    "text_df = pd.read_csv(text_path, sep=\"\\|\\|\", engine=\"python\", names=[\"ID\", \"Text\"], skiprows=1)\n",
    "\n",
    "# === üîó Merge data ===\n",
    "data = pd.merge(variants_df, text_df, on=\"ID\")\n",
    "\n",
    "# === üßπ Clean text column (fix AttributeError due to NaN) ===\n",
    "data[\"Text\"] = data[\"Text\"].fillna(\"unknown\")\n",
    "\n",
    "# === üß™ Prepare categorical features ===\n",
    "gene_encoder = LabelEncoder()\n",
    "variation_encoder = LabelEncoder()\n",
    "data[\"Gene_enc\"] = gene_encoder.fit_transform(data[\"Gene\"])\n",
    "data[\"Variation_enc\"] = variation_encoder.fit_transform(data[\"Variation\"])\n",
    "\n",
    "# === üß† Prepare text features ===\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(data[\"Text\"])\n",
    "X_text = tokenizer.texts_to_sequences(data[\"Text\"])\n",
    "X_text = pad_sequences(X_text, maxlen=500)\n",
    "\n",
    "# === üéØ Labels (1‚Äì9), one-hot encode\n",
    "y = to_categorical(data[\"Class\"] - 1, num_classes=9)\n",
    "\n",
    "# === ‚úÇÔ∏è Train/test split ===\n",
    "X_train_text, X_test_text, X_train_gene, X_test_gene, X_train_var, X_test_var, y_train, y_test = train_test_split(\n",
    "    X_text, data[\"Gene_enc\"], data[\"Variation_enc\"], y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# === üß© Model ===\n",
    "# Inputs\n",
    "input_text = Input(shape=(500,))\n",
    "input_gene = Input(shape=(1,))\n",
    "input_var = Input(shape=(1,))\n",
    "\n",
    "# Embeddings\n",
    "text_emb = Embedding(input_dim=20000, output_dim=128, input_length=500)(input_text)\n",
    "x_text = LSTM(64)(text_emb)\n",
    "\n",
    "gene_emb = Embedding(input_dim=len(gene_encoder.classes_), output_dim=8)(input_gene)\n",
    "x_gene = LSTM(8)(gene_emb)\n",
    "\n",
    "var_emb = Embedding(input_dim=len(variation_encoder.classes_), output_dim=8)(input_var)\n",
    "x_var = LSTM(8)(var_emb)\n",
    "\n",
    "# Combine\n",
    "merged = Concatenate()([x_text, x_gene, x_var])\n",
    "output = Dense(64, activation='relu')(merged)\n",
    "output = Dense(9, activation='softmax')(output)\n",
    "\n",
    "model = Model(inputs=[input_text, input_gene, input_var], outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# === üèãÔ∏è‚Äç‚ôÇÔ∏è Train ===\n",
    "model.fit(\n",
    "    [X_train_text, np.expand_dims(X_train_gene, -1), np.expand_dims(X_train_var, -1)],\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "# === ‚úÖ Evaluate ===\n",
    "loss, acc = model.evaluate(\n",
    "    [X_test_text, np.expand_dims(X_test_gene, -1), np.expand_dims(X_test_var, -1)],\n",
    "    y_test\n",
    ")\n",
    "print(f\"\\n‚úÖ Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# === üíæ Save model and processors ===\n",
    "save_dir = r\"C:\\Users\\sagni\\Downloads\\Cancer Detection\"\n",
    "\n",
    "# 1. Model\n",
    "model.save(f\"{save_dir}\\\\cancer_model.h5\")\n",
    "print(\"‚úÖ Model saved!\")\n",
    "\n",
    "# 2. Tokenizer\n",
    "with open(f\"{save_dir}\\\\tokenizer.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(\"‚úÖ Tokenizer saved!\")\n",
    "\n",
    "# 3. Gene encoder\n",
    "with open(f\"{save_dir}\\\\gene_encoder.pickle\", \"wb\") as f:\n",
    "    pickle.dump(gene_encoder, f)\n",
    "print(\"‚úÖ Gene encoder saved!\")\n",
    "\n",
    "# 4. Variation encoder\n",
    "with open(f\"{save_dir}\\\\variation_encoder.pickle\", \"wb\") as f:\n",
    "    pickle.dump(variation_encoder, f)\n",
    "print(\"‚úÖ Variation encoder saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33869bbf-0117-4091-b2c5-6462a8e70493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
